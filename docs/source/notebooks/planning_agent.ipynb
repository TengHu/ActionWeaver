{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "f5472b88-be63-4cd2-a4f5-28253b39570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import openai\n",
    "import itertools\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from actionweaver.llms.azure.chat import ChatCompletion\n",
    "from actionweaver.llms.azure.tokens import TokenUsageTracker\n",
    "from actionweaver import action, SelectOne, RequireNext\n",
    "\n",
    "from actionweaver.llms.openai.chat import OpenAIChatCompletion\n",
    "from actionweaver.actions.factories.pydantic_model_to_action import action_from_model\n",
    "from actionweaver import action\n",
    "from actionweaver.mixins.examples import LangChainTools, Folium, OpenAIAPI\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "5c691871-4245-4249-8a8c-26d8cca316e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='planning.log',\n",
    "    filemode='a',\n",
    "    format='%(asctime)s.%(msecs)04d %(levelname)s {%(module)s} [%(funcName)s] %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "0ccddc4f-5487-4706-b922-b72bbcfd361e",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "def print_output(output):\n",
    "    from collections.abc import Iterable\n",
    "    if isinstance(output, str):\n",
    "        print (output)\n",
    "    elif isinstance(output, Iterable):\n",
    "        for chunk in output:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            if content is not None:\n",
    "                print(content, end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "746aa759-f95b-4ec5-9bce-34fa471d20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Task(BaseModel):\n",
    "    id: int\n",
    "    objective: str\n",
    "    thought: str\n",
    "    action: str\n",
    "    action_input: str\n",
    "    dependencies: List[int] = []\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    problem: str\n",
    "    tasks: List[Task]\n",
    "\n",
    "    def visualize(self):\n",
    "        # pyvis 0.3.1\n",
    "        from pyvis.network import Network\n",
    "        from IPython.display import display, HTML\n",
    "\n",
    "        net =  Network(notebook=True, directed=True)    \n",
    "        for task in self.tasks:\n",
    "            net.add_node(task.id, label=task.objective)\n",
    "            for dep in task.dependencies:\n",
    "                net.add_edge(dep, task.id)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "a3bbd4b9-6cf0-4a74-96e5-7476fec0ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionMixin:  \n",
    "    @action(name=\"ExecutePythonCode\")\n",
    "    def interpret_python_code(self, code_text: str):\n",
    "        \"\"\"\n",
    "        Execute Python code text and returns the result.\n",
    "    \n",
    "        Args:\n",
    "            code_text (str): A string containing self containing Python code to be interpreted.\n",
    "    \n",
    "        Example:\n",
    "            >>> code_to_interpret = \"2 + 3\"\n",
    "            >>> result = interpret_python_code(code_to_interpret)\n",
    "            >>> print(result)\n",
    "            5\n",
    "        \"\"\"\n",
    "        import sys\n",
    "        from io import StringIO\n",
    "        # Create a local dictionary for the execution environment.\n",
    "        env = {}\n",
    "        \n",
    "        try:\n",
    "            # Redirect stdout to capture the output.\n",
    "            original_stdout = sys.stdout\n",
    "            sys.stdout = captured_output = StringIO()\n",
    "            \n",
    "            # Execute the code in the provided environment.\n",
    "            exec(code_text, env)\n",
    "            \n",
    "            # Retrieve the last expression's value in the environment.\n",
    "            result = env.get('__builtins__', {}).get('None', None)\n",
    "            \n",
    "            return {\"return\": result, \"stdout\": captured_output.getvalue()}\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\", captured_output.getvalue()\n",
    "        finally:\n",
    "            # Restore the original stdout.\n",
    "            sys.stdout = original_stdout\n",
    "\n",
    "    @action(name=\"GoogleSearch\")\n",
    "    def search(self, query: str):\n",
    "        \"\"\"\n",
    "        Perform a Google search and return query results with titles and links.\n",
    "    \n",
    "        :param query: The search query to be used for the Google search.\n",
    "        \"\"\"\n",
    "        from langchain.utilities import GoogleSearchAPIWrapper\n",
    "    \n",
    "        search = GoogleSearchAPIWrapper()\n",
    "        res = search.results(query, 10)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "0b5ffb50-ccc2-4535-b655-ea79f2e5d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(ActionMixin):\n",
    "    \"\"\"\n",
    "    An agent that plans ahead and then executes actions based on its plan.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self, logger):\n",
    "        self.logger = logger\n",
    "        # self.chat = ChatCompletion(\n",
    "        #             model=\"gpt-35-turbo-0613-16k\", \n",
    "        #             azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "        #             api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "        #             api_version=\"2023-10-01-preview\", \n",
    "        #             logger=logger)\n",
    "\n",
    "\n",
    "        self.chat = OpenAIChatCompletion(\"gpt-4-0613\",  logger=logger)\n",
    "\n",
    "        self.system_message = {\"role\": \"system\", \"content\": \"You are a resourceful assistant. Consider using PlanAndExecute if you're unsure about your ability to provide a satisfactory response right away.\"}\n",
    "        \n",
    "        self.messages = [self.system_message]\n",
    "        self.plans = []\n",
    "\n",
    "    def __call__(self, text):\n",
    "        self.messages += [{\"role\": \"user\", \"content\":text}]\n",
    "        # response = self.plan_and_execute.invoke(chat, self.messages)\n",
    "\n",
    "        response = self.plan_and_execute.invoke(chat, self.messages, stream=True)\n",
    "        # response = self.chat.create(messages=self.messages, actions =[self.plan_and_execute], stream=True)\n",
    "        return response\n",
    "\n",
    "\n",
    "    def create_plan(self, text) -> Plan:\n",
    "        self.messages += [{\"role\": \"user\", \"content\":text}]\n",
    "        response = action_from_model(Plan).invoke(chat, self.messages, stream=False)\n",
    "        return response\n",
    "\n",
    "\n",
    "    @action(\"PlanAndExecute\")\n",
    "    def plan_and_execute(self, plan: Plan):\n",
    "        \"\"\"\n",
    "        Create and then executes a given plan.\n",
    "    \n",
    "        This function takes a 'Plan' object as input and executes it. The 'Plan' should\n",
    "        contain a sequence of tasks to be performed in a specific order.\n",
    "\n",
    "        Parameters:\n",
    "        plan (Plan): A 'Plan' object representing the sequence of actions to be executed.\n",
    "        \"\"\"\n",
    "        # ANSI color codes\n",
    "        RESET = \"\\033[0m\"\n",
    "        RED = \"\\033[91m\"\n",
    "        GREEN = \"\\033[92m\"\n",
    "        BLUE = \"\\033[94m\"\n",
    "        MAGENTA =\"\\033[95m\"\n",
    "        \n",
    "        # Text to print\n",
    "        OBSERVATION = f\"{RED}Observation{RESET}\"\n",
    "        OBJECTIVE = f\"{GREEN}Objective{RESET}\"\n",
    "        THOUGHT = f\"{BLUE}Thought{RESET}\"\n",
    "        ACTION = f\"{MAGENTA}Action{RESET}\"\n",
    "        ACTION_INPUT = f\"{MAGENTA}ActionInput{RESET}\"\n",
    "\n",
    "        \n",
    "        \n",
    "        plan = Plan.parse_obj(plan)\n",
    "        self.plans += [plan]\n",
    "\n",
    "\n",
    "        # Execute the task graph using topo sort, starting with tasks with no dependencies\n",
    "        results = {}        \n",
    "        indegrees = {}\n",
    "        out = {}\n",
    "        tasks = {}        \n",
    "        to_be_executed = []\n",
    "        \n",
    "        for task in plan.tasks:\n",
    "            out[task.id] = []\n",
    "            \n",
    "        for task in plan.tasks:\n",
    "            tasks[task.id] = task\n",
    "\n",
    "            indegrees[task.id] = len(task.dependencies)\n",
    "            for dep in task.dependencies:\n",
    "                out[dep].append(task.id)\n",
    "\n",
    "            if indegrees[task.id] == 0:\n",
    "                to_be_executed.append(task.id)\n",
    "\n",
    "        last_executed_tasks = [] # Tasks executed in last iteration\n",
    "        while len(to_be_executed) > 0:\n",
    "            buf = []\n",
    "            \n",
    "            for t in to_be_executed:\n",
    "                print ('#' * 100 + \"\\n\")\n",
    "\n",
    "                context = []\n",
    "                for dep in tasks[t].dependencies:\n",
    "                    context += [f\"{OBSERVATION} : {results[dep]}\"]\n",
    "                context = '\\n'.join(context)\n",
    "            \n",
    "                message = f\"{context}\\n{OBJECTIVE}: {tasks[t].objective}\\n{THOUGHT}: {tasks[t].thought}\\n{ACTION}: {tasks[t].action}\\n{ACTION_INPUT}: {tasks[t].action_input}\"\n",
    "\n",
    "                print (message + \"\\n\")\n",
    "                \n",
    "                # execute \n",
    "                res = self.chat.create(messages=[self.system_message, {\"role\": \"user\", \"content\":message}], actions =[self.interpret_python_code, self.search], stream=False)\n",
    "                results[t] = res\n",
    "\n",
    "                print (f\"Result: {res}\")\n",
    "                print ('#' * 100 + \"\\n\")\n",
    "                \n",
    "                last_executed_tasks += [t]\n",
    "\n",
    "                for d in out[t]:\n",
    "                    indegrees[d] -= 1\n",
    "                    if indegrees[d] == 0:\n",
    "                        buf.append(d)\n",
    "\n",
    "            to_be_executed = buf\n",
    "        return '\\n'.join([results[t] for t in last_executed_tasks])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6675e71e-3637-4737-8247-00f6b33dcb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "b894fd24-3d87-4332-8c23-7991fd45efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"who are mayors of top 3 populated cities in USA \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "cb1e1117-b0e4-4202-be86-7e894db874ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(logger)\n",
    "plan = agent.create_plan(f\"\"\"PlanAndExecute: {question}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "cae933de-4df7-43ed-b309-f60924cad320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local cdn resources have problems on chrome/safari when used in jupyter-notebook. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"nx.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x12f0c0b80>"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.visualize().show('nx.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "097b81bc-40d3-4c6b-8262-4b72e0e39412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rk/nvn6c0b92tb48wzzf6k_8b380000gn/T/ipykernel_18621/3159929866.py:61: PydanticDeprecatedSince20: The `parse_obj` method is deprecated; use `model_validate` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.2/migration/\n",
      "  plan = Plan.parse_obj(plan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "\n",
      "\n",
      "\u001b[92mObjective\u001b[0m: Research the top 3 populated cities in the USA\n",
      "\u001b[94mThought\u001b[0m: I can search for the current population data of cities in the USA\n",
      "\u001b[95mAction\u001b[0m: Search for the current population data of cities in the USA\n",
      "\u001b[95mActionInput\u001b[0m: USA cities population data\n",
      "\n",
      "Result: The top three most populated cities in the USA are:\n",
      "\n",
      "1. New York - 8,550,405\n",
      "2. Los Angeles - 3,971,883\n",
      "3. Chicago - 2,720,546\n",
      "\n",
      "These numbers are based on the data available at the time of the search.\n",
      "####################################################################################################\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "\u001b[91mObservation\u001b[0m : The top three most populated cities in the USA are:\n",
      "\n",
      "1. New York - 8,550,405\n",
      "2. Los Angeles - 3,971,883\n",
      "3. Chicago - 2,720,546\n",
      "\n",
      "These numbers are based on the data available at the time of the search.\n",
      "\u001b[92mObjective\u001b[0m: Identify the mayors of the top 3 populated cities\n",
      "\u001b[94mThought\u001b[0m: Once I have the population data, I can search for the mayors of the cities\n",
      "\u001b[95mAction\u001b[0m: Search for the mayors of the top 3 populated cities\n",
      "\u001b[95mActionInput\u001b[0m: Mayors of [City 1], [City 2], [City 3]\n",
      "\n",
      "Result: The current mayor of New York is Eric Adams. Now, let's find out the mayors of Los Angeles and Chicago.\n",
      "####################################################################################################\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "\u001b[91mObservation\u001b[0m : The current mayor of New York is Eric Adams. Now, let's find out the mayors of Los Angeles and Chicago.\n",
      "\u001b[92mObjective\u001b[0m: Provide the information about the mayors\n",
      "\u001b[94mThought\u001b[0m: After finding the mayors, I can share the information with the user\n",
      "\u001b[95mAction\u001b[0m: Share the information about the mayors of the top 3 populated cities\n",
      "\u001b[95mActionInput\u001b[0m: Mayors: [Mayor 1], [Mayor 2], [Mayor 3]\n",
      "\n",
      "Result: The current mayor of Los Angeles is Karen Bass. Now, let's find out the mayor of Chicago.\n",
      "####################################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = agent.plan_and_execute(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "c1ee6ab9-a7a6-4075-8a5c-e47a6519b10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The top three most populated cities in the USA are:\\n\\n1. New York - 8,550,405\\n2. Los Angeles - 3,971,883\\n3. Chicago - 2,720,546\\n\\nThese numbers are based on the data available at the time of the search.\\nThe current mayor of New York is Eric Adams. Now, let's find out the mayors of Los Angeles and Chicago.\\nThe current mayor of Los Angeles is Karen Bass. Now, let's find out the mayor of Chicago.\""
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f949f0-0afd-408e-88d9-85255b13f21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82610f94-e6ca-467b-aca3-76d085e751d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef36b2e-f89c-4b28-b9a1-de0f549d30cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "67942b51-c9a6-4eab-94e3-bbb31beb9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_PROMPT = \"\"\"Use following format to reason:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of {tool_names}\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Task(BaseModel):\n",
    "    question: str\n",
    "    thought: str\n",
    "    action: str\n",
    "    action_input: str\n",
    "\n",
    "\n",
    "class ReActAgent(ActionMixin):\n",
    "    \"\"\" \n",
    "    Agent to implement the ReAct logic.\n",
    "    https://react-lm.github.io/\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    SYS_PROMPT = \"\"\"You are a resourceful assistant.\"\"\"\n",
    "\n",
    "    CONTEXT = \"\"\"\n",
    "----------------------\n",
    "{tasks}\n",
    "\n",
    "----------------------\n",
    "Answer the question as best you can, use the context above and continue with the reasoning process.\n",
    "Only give the final answer when you're confident, otherwise continue the reasoning.\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self, logger, execute=False):\n",
    "        self.logger = logger\n",
    "        self.chat = ChatCompletion(\n",
    "                    model=\"gpt-35-turbo-0613-16k\", \n",
    "                    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "                    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "                    api_version=\"2023-10-01-preview\", \n",
    "                    logger=logger)\n",
    "\n",
    "\n",
    "        # self.chat = OpenAIChatCompletion(\"gpt-4-0613\",  logger=logger)\n",
    "        self.system_message = {\"role\": \"system\", \"content\": self.SYS_PROMPT}\n",
    "        self.msgs = []\n",
    "        self.tasks = []\n",
    "\n",
    "    def __call__(self, text):\n",
    "        self.tasks = []\n",
    "        max_iters = 5\n",
    "        actions = {self.search.name: self.search}\n",
    "        \n",
    "        while max_iters:\n",
    "            system_message = [{\"role\": \"system\", \"content\": self.SYS_PROMPT}]\n",
    "\n",
    "            ans = self.chat.create(messages=system_message + [{\"role\": \"user\", \"content\": self.CONTEXT.format(tasks = text + '\\n'.join(self.tasks)) + text}], actions =[action_from_model(Task, description=TASK_PROMPT.format(tool_names=list(actions.keys())))], stream=False)\n",
    "            if isinstance(ans, Task):\n",
    "                obs = actions[ans.action](ans.action_input)\n",
    "                \n",
    "                self.tasks.append(f\"\\nThought:{ans.thought}\\nAction:{ans.action}\\nActionInput:{ans.action_input}\\nObservation:{obs}\\n\")\n",
    "            else:\n",
    "                return ans\n",
    "\n",
    "            \n",
    "            max_iters -= 1\n",
    "\n",
    "        return \"Stopped!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "fe2e450d-7800-4c47-8067-2cd2a5a6f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent(logger)\n",
    "ans = agent(\"\"\"who are mayors of  top 3 most populated cities in the USA\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50349761-5dba-4c5c-a5ee-3bf8c5b23da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0270867-62de-4dd7-9485-f371b3759b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476d713-dd1a-4d75-b654-74f3f76d0611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ee957-d71a-41ba-a1e7-72edda23e4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
