{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02433815-7bb9-4e61-be67-db4854f0c403",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Actions of Stateful Agent\n",
    "Developers also could create a class and enhance its functionality using ActionWeaver's action decorators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c94281-1d38-4e34-bbd0-92ff70227482",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from actionweaver.llms import wrap\n",
    "from actionweaver import action\n",
    "from typing import List\n",
    "\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "079d94a0-19ba-4874-8db3-0b1f28230da8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AgentV0:\n",
    "    def __init__(self):\n",
    "        self.llm = wrap(OpenAI())\n",
    "        self.messages = []\n",
    "        self.times = []\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        self.messages += [{\"role\": \"user\", \"content\":text}]\n",
    "        return self.llm.create(model=\"gpt-3.5-turbo\", messages=self.messages, actions = [self.get_current_time])\n",
    "        \n",
    "    @action(name=\"GetCurrentTime\")\n",
    "    def get_current_time(self) -> str:\n",
    "        \"\"\"\n",
    "        Use this for getting the current time in the specified time zone.\n",
    "        \n",
    "        :return: A string representing the current time in the specified time zone.\n",
    "        \"\"\"\n",
    "        import datetime\n",
    "        current_time = datetime.datetime.now()\n",
    "\n",
    "        self.times += [str(current_time)]\n",
    "        \n",
    "        return f\"The current time is {current_time}\"\n",
    "\n",
    "agent = AgentV0()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9138451-e0b5-44bd-b768-2c9f25bbcedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8e9w3bflg5iwHCenO7WGjSVZVSyvT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The current time is 2024-01-06 18:00:02.', role='assistant', function_call=None, tool_calls=None))], created=1704582003, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=19, prompt_tokens=100, total_tokens=119))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can invoke actions just like regular instance methods\n",
    "agent.get_current_time() # Output: 'The current time is 20:34.'\n",
    "\n",
    "\n",
    "agent(\"what time is it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8381c18a-302f-4976-bd39-5c16fe68e2dd",
   "metadata": {},
   "source": [
    "**Grouping and Extending Actions Through Inheritance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "842e1792-3210-4be8-85c9-f6c669dfe127",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8e9wfhRvZ56jZc2PxU4Fd6d7Vy6jM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Today's events include:\\n\\n1. Perugino: Adoration of the Magi - A featured event celebrating Epiphany, a major feast, held annually on this day.\\n\\n2. Legislative proceedings - Various legislative sessions and motions are taking place today in the Assembly and Senate.\\n\\n3. New York State Fair - There are numerous fun activities and events happening at the New York State Fair. You can plan your itinerary by selecting the events you are interested in.\\n\\n4. Senate events - You can watch or listen to today's Senate events, as well as access the TV schedule, media archive, and more.\\n\\n5. Campus Recreation - There is a Judo Club meeting at the UNL Coliseum in Temporary Conference Room 306.\\n\\n6. Apple Shortcut - There is a suggestion to use an Apple Shortcut to get a list of today's Calendar Events and put them into a Keyboard.\\n\\nPlease note that these are just a few highlights, and there may be additional events happening today.\", role='assistant', function_call=None, tool_calls=None))], created=1704582041, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=197, prompt_tokens=428, total_tokens=625))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LangChainTools:\n",
    "    def __init__(self):\n",
    "        from langchain_community.tools.google_search.tool import GoogleSearchRun\n",
    "        from langchain_community.utilities.google_search import GoogleSearchAPIWrapper\n",
    "        self.google_search_api = GoogleSearchRun(api_wrapper=GoogleSearchAPIWrapper())\n",
    "    \n",
    "    @action(name=\"GoogleSearch\")\n",
    "    def google_search(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Perform a Google search using the provided query. \n",
    "\n",
    "        :param query: The search query to be used for the Google search.\n",
    "        :return: The search results as a string.\n",
    "        \"\"\"\n",
    "        return self.google_search_api(query)\n",
    "    \n",
    "class AgentV1(AgentV0, LangChainTools):\n",
    "    def __init__(self):\n",
    "        AgentV0.__init__(self)\n",
    "        LangChainTools.__init__(self)\n",
    "        \n",
    "    \n",
    "    def __call__(self, text):\n",
    "        self.messages += [{\"role\": \"user\", \"content\":text}]\n",
    "        return self.llm.chat.completions.create(model=\"gpt-3.5-turbo\", messages=self.messages, actions = [self.google_search])\n",
    "\n",
    "agent = AgentV1()\n",
    "agent(\"what happened today\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389be3b9-cd9f-4b52-aef1-0745f2164f87",
   "metadata": {},
   "source": [
    "We could use parameter `orch` when calling the chat completion API. This feature will allow us for more precise control over the specific set of tools available to the LLM during each interaction.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "client.chat.completions.create(\n",
    "    messages = ...\n",
    "    actions=[a1, a2, a3], # First, LLM respond with either a1, a2 or a3, or text without action\n",
    "    # Define the orchestration logic for actions:\n",
    "    orch={\n",
    "        a1.name: [a2, a3],  # If a1 is invoked, the next response will be either a2, a3 or a text response.\n",
    "        a2.name: a3,      # If a2 is invoked, the next action will be a3\n",
    "        a3.name: [a4]     # If a3 is invoked, the next response will be a4 or a text response.\n",
    "        a4.name: None     # If a4 is invoked, the next response will guarantee to be a text message\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "For details please take a look at [here](https://github.com/TengHu/ActionWeaver?tab=readme-ov-file#orchestration-of-actions-experimental )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fffbbb7-c8e3-4a98-9564-01ed054c5443",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FileAgent(AgentV0):\n",
    "    @action(name=\"FileHandler\")\n",
    "    def handle_file(self, instruction: str) -> str:\n",
    "        \"\"\"\n",
    "        Handles ALL user instructions related to file operations.\n",
    "    \n",
    "        Args:\n",
    "            instruction (str): The user's instruction about file handling.\n",
    "    \n",
    "        Returns:\n",
    "            str: The response to the user's question.\n",
    "        \"\"\"\n",
    "        print (f\"Handling {instruction}\")\n",
    "        return instruction\n",
    "        \n",
    "\n",
    "    @action(name=\"ListFiles\")\n",
    "    def list_all_files_in_repo(self, repo_path: str ='.') -> List:\n",
    "        \"\"\"\n",
    "        Lists all the files in the given repository.\n",
    "    \n",
    "        :param repo_path: Path to the repository. Defaults to the current directory.\n",
    "        :return: List of file paths.\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"list_all_files_in_repo: {repo_path}\")\n",
    "        \n",
    "        file_list = []\n",
    "        for root, _, files in os.walk(repo_path):\n",
    "            for file in files:\n",
    "                file_list.append(os.path.join(root, file))\n",
    "            break\n",
    "        return file_list\n",
    "\n",
    "    @action(name=\"ReadFile\")\n",
    "    def read_from_file(self, file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Reads the content of a file and returns it as a string.\n",
    "    \n",
    "        :param file_path: The path to the file that needs to be read.\n",
    "        :return: A string containing the content of the file.\n",
    "        \"\"\"\n",
    "        print(f\"read_from_file: {file_path}\")\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "        return f\"The file content: \\n{content}\"\n",
    "\n",
    "    def __call__(self, text):\n",
    "        self.messages += [{\"role\": \"user\", \"content\":text}]\n",
    "        return self.llm.create(model=\"gpt-3.5-turbo\", messages=self.messages, actions = [self.handle_file], orch = {self.handle_file.name: [self.list_all_files_in_repo, self.read_from_file]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed4906a-b57e-4f78-b9a1-bea1c2a195ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FileAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8eca2b-a052-4f38-9f57-3b42cfc362d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling list all files\n",
      "list_all_files_in_repo: .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8cihLJHsfQZz3hPPHAyamQ7HVPm85', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Here are all the files in the current repository:\\n\\n1. langsmith.ipynb\\n2. azure_tutorial-Copy1.ipynb\\n3. parallel_tools.log\\n4. untitled.md\\n5. parallel_tools.ipynb\\n6. network.html\\n7. stateful_agent.ipynb\\n8. huggingface.ipynb\\n9. anyscale.ipynb\\n10. ReAct.ipynb\\n11. tracing.log\\n12. structured_extraction.log\\n13. quickstart.ipynb\\n14. structured_extraction.ipynb\\n15. azure_tutorial.ipynb\\n16. litellm.ipynb\\n17. cookbook.ipynb\\n18. logging.ipynb\\n19. nx.html\\n20. agent.log\\n21. logging-Copy1.ipynb\\n22. orchestration.ipynb\\n\\nLet me know if there's anything else I can help with!\", role='assistant', function_call=None, tool_calls=None))], created=1704238975, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=190, prompt_tokens=306, total_tokens=496))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"Take file action of [list all files in current repository]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
