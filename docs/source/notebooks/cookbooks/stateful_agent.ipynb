{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02433815-7bb9-4e61-be67-db4854f0c403",
   "metadata": {},
   "source": [
    "# Stateful Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c94281-1d38-4e34-bbd0-92ff70227482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import openai\n",
    "import itertools\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from actionweaver.llms.openai.functions.chat import OpenAIChatCompletion\n",
    "from actionweaver.llms.openai.functions.tokens import TokenUsageTracker\n",
    "from actionweaver import action, SelectOne, RequireNext\n",
    "\n",
    "from actionweaver.mixins.examples import LangChainTools, Folium, OpenAIAPI\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "def print_output(output):\n",
    "    from collections.abc import Iterable\n",
    "    if isinstance(output, str):\n",
    "        print (output)\n",
    "    elif isinstance(output, Iterable):\n",
    "        for chunk in output:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            if content is not None:\n",
    "                print(content, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08caafb5-37ca-4c69-a893-58e3313ef9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='agent.log',\n",
    "    filemode='a',\n",
    "    format='%(asctime)s.%(msecs)04d %(levelname)s {%(module)s} [%(funcName)s] %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "079d94a0-19ba-4874-8db3-0b1f28230da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentV0:\n",
    "    def __init__(self, logger):\n",
    "        self.logger = logger\n",
    "        self.token_tracker = TokenUsageTracker(budget=None, logger=logger)\n",
    "        self.llm = OpenAIChatCompletion(\"gpt-3.5-turbo\", token_usage_tracker = self.token_tracker, logger=logger)\n",
    "        \n",
    "        self.messages = [{\"role\": \"system\", \"content\": \"You are a resourceful assistant.\"}]\n",
    "        self.times = []\n",
    "\n",
    "    def __call__(self, text):\n",
    "        self.messages += [{\"role\": \"user\", \"content\":text}]\n",
    "        response = self.llm.create(messages=self.messages, actions = [self.get_current_time, self.sleep], stream=True)\n",
    "\n",
    "        return response\n",
    "        \n",
    "    @action(name=\"GetCurrentTime\")\n",
    "    def get_current_time(self) -> str:\n",
    "        \"\"\"\n",
    "        Use this for getting the current time in the specified time zone.\n",
    "        \n",
    "        :return: A string representing the current time in the specified time zone.\n",
    "        \"\"\"\n",
    "        import datetime\n",
    "        current_time = datetime.datetime.now()\n",
    "\n",
    "        self.times += [str(current_time)]\n",
    "        \n",
    "        return f\"The current time is {current_time}\"\n",
    "\n",
    "\n",
    "    @action(name=\"Sleep\")\n",
    "    def sleep(self, seconds: int) -> str:\n",
    "        \"\"\"\n",
    "        Introduces a sleep delay of the specified seconds and returns a message.\n",
    "    \n",
    "        Args:\n",
    "            seconds (int): The duration to sleep in seconds.\n",
    "    \n",
    "        Returns:\n",
    "            str: A message indicating the completion of the sleep.\n",
    "        \"\"\"\n",
    "        import time\n",
    "        time.sleep(seconds)\n",
    "        return f\"Now I wake up after sleep {seconds} seconds.\"\n",
    "\n",
    "\n",
    "    @action(name=\"Ask\")\n",
    "    def ask(self, question: str) -> str:\n",
    "        \"\"\"\n",
    "        Invoke this if you want to ask question, or there is anything need clarification.\n",
    "    \n",
    "        Args:\n",
    "            question (str): The question to ask the user.\n",
    "        \"\"\"\n",
    "        ans = input(f\"Question: {question}\\n\")\n",
    "        return ans\n",
    "\n",
    "\n",
    "\n",
    "agent = AgentV0(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9138451-e0b5-44bd-b768-2c9f25bbcedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current time is 19:36."
     ]
    }
   ],
   "source": [
    "print_output(agent(\"what time is it\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "842e1792-3210-4be8-85c9-f6c669dfe127",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentV1(AgentV0, LangChainTools, Folium, OpenAIAPI):\n",
    "    def __call__(self, text):\n",
    "        self.messages += [{\"role\": \"user\", \"content\":text}]\n",
    "        response = self.llm.create(messages=self.messages, actions = [self.search, self.show_map, self.get_current_time, self.sleep], stream=True)\n",
    "\n",
    "        return response\n",
    "\n",
    "agent = AgentV1(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fffbbb7-c8e3-4a98-9564-01ed054c5443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain is a framework for developing applications powered by language models. It simplifies the process of creating generative AI application interfaces and enables developers to build context-aware, reasoning language model applications. Langchain provides tools and APIs that make it easy to connect language models to other data sources and interact with them. It is an open-source library that supports Python and JavaScript.\n",
      "\n",
      "Haystack, on the other hand, is an open-source Python framework for building production-ready language model applications. It offers tooling for every stage of the NLP (Natural Language Processing) project life cycle. Haystack is built around the concept of pipelines, which are powerful structures that perform NLP tasks. It provides an orchestration framework for language models and offers components that can be connected together to create pipelines.\n",
      "\n",
      "Please note that there may be other unrelated results for the term \"Haystack\" such as the Haystack app, Haystack News, or Haystack Rock."
     ]
    }
   ],
   "source": [
    "print_output(agent(\"search what is Langchain, what is haystack\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b280e164-f499-410c-801e-2bf81a376c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c3a82d-d8da-4a74-9e2d-c263bceb107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileUtility(AgentV0):\n",
    "    @action(name=\"FileHandler\", orch_expr=SelectOne(['FileHandler', 'ListFiles', 'ReadFile']))\n",
    "    def handle_file(self, instruction: str) -> str:\n",
    "        \"\"\"\n",
    "        Handles user instructions related to file operations. Put every context in the instruction only!\n",
    "    \n",
    "        Args:\n",
    "            instruction (str): The user's instruction about file handling.\n",
    "    \n",
    "        Returns:\n",
    "            str: The response to the user's question.\n",
    "        \"\"\"\n",
    "        return instruction\n",
    "        \n",
    "\n",
    "    @action(name=\"ListFiles\", scope=\"file\")\n",
    "    def list_all_files_in_repo(self, repo_path: str ='.') -> List:\n",
    "        \"\"\"\n",
    "        Lists all the files in the given repository.\n",
    "    \n",
    "        :param repo_path: Path to the repository. Defaults to the current directory.\n",
    "        :return: List of file paths.\n",
    "        \"\"\"\n",
    "\n",
    "        logger.info(f\"list_all_files_in_repo: {repo_path}\")\n",
    "        \n",
    "        file_list = []\n",
    "        for root, _, files in os.walk(repo_path):\n",
    "            for file in files:\n",
    "                file_list.append(os.path.join(root, file))\n",
    "            break\n",
    "        return file_list\n",
    "\n",
    "    @action(name=\"ReadFile\", scope=\"file\")\n",
    "    def read_from_file(self, file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Reads the content of a file and returns it as a string.\n",
    "    \n",
    "        :param file_path: The path to the file that needs to be read.\n",
    "        :return: A string containing the content of the file.\n",
    "        \"\"\"\n",
    "        logger.info(f\"read_from_file: {file_path}\")\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "        return f\"The file content: \\n{content}\"\n",
    "\n",
    "    @action(name=\"WriteFile\", scope=\"file\")\n",
    "    def write_to_file(self, file_path: str, content: str) -> str:\n",
    "        \"\"\"\n",
    "        Writes the given content to a file.\n",
    "        \n",
    "        :param file_path: The path to the file where the content should be written.\n",
    "        :param content: The content to be written to the file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'a') as file:\n",
    "                file.write(content)\n",
    "            return \"Content successfully appended to the file.\"\n",
    "        except Exception as e:\n",
    "            return f\"An error occurred while appending to the file: {str(e)}\"\n",
    "        \n",
    "\n",
    "\n",
    "class AgentV2(FileUtility):\n",
    "    def __call__(self, text):\n",
    "        self.messages += [{\"role\": \"user\", \"content\":text}]\n",
    "        response = self.llm.create(messages=self.messages, actions = [self.search, self.show_map, self.get_current_time, self.sleep], stream=True)\n",
    "\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74993086-26fb-415e-b37e-d5cb1914b2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3afcae-1d71-47ed-9870-0922e97a75d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c862b6c-12c0-4a4c-ad12-dfc420e7985c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cbecb67-b8ac-4492-ae5b-980650907dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import os\n",
    "class FileAgent(AgentV0):\n",
    "    @action(name=\"FileHandler\")\n",
    "    def handle_file(self, instruction: str) -> str:\n",
    "        \"\"\"\n",
    "        Handles ALL user instructions related to file operations.\n",
    "    \n",
    "        Args:\n",
    "            instruction (str): The user's instruction about file handling.\n",
    "    \n",
    "        Returns:\n",
    "            str: The response to the user's question.\n",
    "        \"\"\"\n",
    "        print (f\"Handling {instruction}\")\n",
    "        return instruction\n",
    "        \n",
    "\n",
    "    @action(name=\"ListFiles\")\n",
    "    def list_all_files_in_repo(self, repo_path: str ='.') -> List:\n",
    "        \"\"\"\n",
    "        Lists all the files in the given repository.\n",
    "    \n",
    "        :param repo_path: Path to the repository. Defaults to the current directory.\n",
    "        :return: List of file paths.\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"list_all_files_in_repo: {repo_path}\")\n",
    "        \n",
    "        file_list = []\n",
    "        for root, _, files in os.walk(repo_path):\n",
    "            for file in files:\n",
    "                file_list.append(os.path.join(root, file))\n",
    "            break\n",
    "        return file_list\n",
    "\n",
    "    @action(name=\"ReadFile\")\n",
    "    def read_from_file(self, file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Reads the content of a file and returns it as a string.\n",
    "    \n",
    "        :param file_path: The path to the file that needs to be read.\n",
    "        :return: A string containing the content of the file.\n",
    "        \"\"\"\n",
    "        print(f\"read_from_file: {file_path}\")\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "        return f\"The file content: \\n{content}\"\n",
    "\n",
    "    def __call__(self, text):\n",
    "        self.messages += [{\"role\": \"user\", \"content\":text}]\n",
    "        return self.llm.chat.completions.create(model=\"gpt-3.5-turbo\", messages=self.messages, actions = [self.list_all_files_in_repo], orch = {self.handle_file: [self.list_all_files_in_repo, self.read_from_file]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ed4906a-b57e-4f78-b9a1-bea1c2a195ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FileUtility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e8eca2b-a052-4f38-9f57-3b42cfc362d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are the files in the current directory:\\n\\n1. index.html\\n2. styles.css\\n3. script.js\\n4. image.jpg\\n5. README.md'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"list all files in current dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3f44c-6641-46fd-9b1b-2a320e33459a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
