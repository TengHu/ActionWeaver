{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02433815-7bb9-4e61-be67-db4854f0c403",
   "metadata": {},
   "source": [
    "# QuickStart\n",
    "\n",
    "_ActionWeaver is an AI application framework that puts function-calling as a first-class feature_.\n",
    "\n",
    "---\n",
    "\n",
    "This demonstrates how to seamlessly integrate any Python function into your LLM application using ActionWeaver and either the Azure or OpenAI API.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16250eaa-15b7-4848-81cf-ac62cd8cefa9",
   "metadata": {},
   "source": [
    "## Patch OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d682d986-a3ac-4f4d-a967-a6eaccef0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from actionweaver.llms import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17570e90-8181-4271-ada1-f774f5ddf628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    filename='agent.log',\n",
    "    filemode='a',\n",
    "    format='%(asctime)s.%(msecs)04d %(levelname)s {%(module)s} [%(funcName)s] %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da70e52c-6219-4b35-a9e9-d0b43c945b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from actionweaver.llms.openai.tools.chat import OpenAIChatCompletion\n",
    "from actionweaver.llms.openai.tools.tokens import TokenUsageTracker\n",
    "from actionweaver.llms.openai.tools.tools import Tools\n",
    "client = OpenAI()\n",
    "# client = patch(client)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22710e02-f81f-4050-8c2c-01cd64e48f32",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'actions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 38\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdumps({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m: location, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     32\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     33\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     34\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms the weather in San Francisco and Beijing ?\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     35\u001b[0m   ]\n\u001b[0;32m---> 38\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mget_current_weather\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/actiontools/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py:303\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Completions.create() got an unexpected keyword argument 'actions'"
     ]
    }
   ],
   "source": [
    "from actionweaver import action\n",
    "\n",
    "@action(name=\"GetCurrentTime\")\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"\n",
    "    Use this for getting the current time in the specified time zone.\n",
    "    \n",
    "    :return: A string representing the current time in the specified time zone.\n",
    "    \"\"\"\n",
    "    print (\"Getting current time...\")\n",
    "    import datetime\n",
    "    current_time = datetime.datetime.now()\n",
    "    \n",
    "    return f\"The current time is {current_time}\"\n",
    "\n",
    "\n",
    "@action(name=\"GetWeather\", stop=False)\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    print (\"Getting current weather\")\n",
    "    \n",
    "    import json\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"what's the weather in San Francisco and Beijing ?\"}\n",
    "  ]\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=messages,\n",
    "    actions = [get_current_weather],\n",
    "    stream=False, \n",
    "    logger=logger\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69c84261-b03b-4333-8cea-8315241c69a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The weather in San Francisco is currently 72 degrees Fahrenheit. However, I'm sorry I don't have the current weather information for Beijing.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb1e72-862e-44c9-83d3-f07d382e175f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08ecc5-2768-4427-9bb9-67e6bd38c5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72428d34-08c7-49ee-a1cf-b2c636c701ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in San Francisco is 72Â°F. However, I'm sorry but I couldn't find the current weather information for Beijing.\n"
     ]
    }
   ],
   "source": [
    "def print_output(output):\n",
    "    from collections.abc import Iterable\n",
    "    if isinstance(output, str):\n",
    "        print (output)\n",
    "    elif isinstance(output, Iterable):\n",
    "        for chunk in output:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            if content is not None:\n",
    "                print(content, end='')\n",
    "\n",
    "\n",
    "print_output(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e6f65-d8c7-4da0-a623-3acbaed12e90",
   "metadata": {},
   "source": [
    "## Use ActionWeaver and OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5022c13-955b-4518-b8f0-85c2f2480ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"GetCurrentTime\",\n",
      "    \"description\": \"\\n    Use this for getting the current time in the specified time zone.\\n    \\n    :return: A string representing the current time in the specified time zone.\\n    \",\n",
      "    \"parameters\": {\n",
      "        \"properties\": {},\n",
      "        \"title\": \"Get_Current_Time\",\n",
      "        \"type\": \"object\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from actionweaver.llms.openai.tools.chat import OpenAIChatCompletion\n",
    "from actionweaver import action\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "@action(name=\"GetCurrentTime\")\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"\n",
    "    Use this for getting the current time in the specified time zone.\n",
    "    \n",
    "    :return: A string representing the current time in the specified time zone.\n",
    "    \"\"\"\n",
    "    print (\"Getting current time...\")\n",
    "    import datetime\n",
    "    current_time = datetime.datetime.now()\n",
    "    \n",
    "    return f\"The current time is {current_time}\"\n",
    "\n",
    "print (json.dumps(get_current_time.get_function_details(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6481c118-0ab2-4989-ad60-a5cf5bf14513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = OpenAIChatCompletion(\"gpt-3.5-turbo\")\n",
    "messages = [{\"role\": \"user\", \"content\": \"what up\"}]\n",
    "chat.create(messages=messages, actions = [get_current_time], stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63675ff7-1349-4df7-a6aa-8f82d15ba1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92e1741f-3e0a-4673-9e2d-683d8e51ff47",
   "metadata": {},
   "source": [
    "## Use ActionWeaver and Azure OpenAI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7235fd4-52ba-4909-8bed-63aac279b0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from actionweaver.llms.azure.chat import ChatCompletion\n",
    "\n",
    "chat = ChatCompletion(\n",
    "    model=\"gpt-35-turbo-0613-16k\", \n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2023-10-01-preview\",\n",
    ")\n",
    "\n",
    "chat.create([{\"role\": \"user\", \"content\": \"hie\"}], actions = [get_current_time], stream=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d6414-c04c-4fbe-bfeb-8cb9effc2b39",
   "metadata": {},
   "source": [
    "### Force execute an action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff6aa568-cdc5-45bc-8ee5-4c111bc347fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current time...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current time is 14:44.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_time.invoke(chat, [{\"role\": \"user\", \"content\": \"what time\"}], stream=False, force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e9543b-1947-4545-9d8e-7aed7833c565",
   "metadata": {},
   "source": [
    "### Stop the Action in the loop\n",
    "\n",
    "Every action comes with a stop argument, which is set to False by default, if True this means that the LLM will immediately return the function's output if chosen, but this also restricts the LLM from making multiple function calls. For instance, if asked about the weather in NYC and San Francisco, the model would invoke two separate functions sequentially for each city. However, with `stop=True`, this process is interrupted once the first function returns weather information for either NYC or San Francisco, depending on which city it queries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c75a4511-70b1-4e53-b0ac-37693f5dbdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@action(name=\"GetWeather\", stop=False)\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    print (\"Getting current weather\")\n",
    "    \n",
    "    import json\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb915ce0-2484-4af3-8949-6e5e08885208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current weather\n",
      "Getting current weather\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The weather in San Francisco is currently 72 degrees Fahrenheit. In Tokyo, it is 10 degrees Celsius.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.create([{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo?\"}], actions = [get_current_weather])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4178e1d-ef6c-4954-b342-729f73b4736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_current_weather.stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "017875f5-e8bf-4508-afc7-a27a0103a2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current weather\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.create([{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo?\"}], actions = [get_current_weather])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad3616a-18ab-4809-893c-171a0c625245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
