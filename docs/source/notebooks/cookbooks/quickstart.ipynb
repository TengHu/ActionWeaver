{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02433815-7bb9-4e61-be67-db4854f0c403",
   "metadata": {},
   "source": [
    "# QuickStart\n",
    "\n",
    "_ActionWeaver is an AI application framework that puts function-calling as a first-class feature_.\n",
    "\n",
    "---\n",
    "\n",
    "This demonstrates how to seamlessly integrate any Python function into your LLM application using ActionWeaver and either the Azure or OpenAI API.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16250eaa-15b7-4848-81cf-ac62cd8cefa9",
   "metadata": {},
   "source": [
    "## Use ActionWeaver and OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d682d986-a3ac-4f4d-a967-a6eaccef0413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function actionweaver.llms.patch.patch(client: Union[openai.OpenAI, openai.AsyncOpenAI, openai.lib.azure.AsyncAzureOpenAI, openai.lib.azure.AzureOpenAI])>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from actionweaver.llms.openai.tools.tokens import TokenUsageTracker\n",
    "from actionweaver.llms import patch\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_client = patch(OpenAI())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22710e02-f81f-4050-8c2c-01cd64e48f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from actionweaver import action\n",
    "\n",
    "@action(name=\"GetCurrentTime\")\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"\n",
    "    Use this for getting the current time in the specified time zone.\n",
    "    \n",
    "    :return: A string representing the current time in the specified time zone.\n",
    "    \"\"\"\n",
    "    print (\"Getting current time...\")\n",
    "    import datetime\n",
    "    current_time = datetime.datetime.now()\n",
    "    \n",
    "    return f\"The current time is {current_time}\"\n",
    "\n",
    "\n",
    "@action(name=\"GetWeather\", stop=False)\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    print (\"Getting current weather\")\n",
    "    \n",
    "    import json\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69c84261-b03b-4333-8cea-8315241c69a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current weather\n",
      "Getting current weather\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The current weather in San Francisco is 72Â°F. However, I couldn't retrieve the current weather for Beijing.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"what's the weather in San Francisco and Beijing ?\"}\n",
    "  ]\n",
    "\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=messages,\n",
    "    actions = [get_current_weather],\n",
    "    stream=False, \n",
    "    logger=logger,\n",
    "    token_usage_tracker = TokenUsageTracker(500),\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0690972-4b61-48b5-9b3f-a21c3bb2df5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92e1741f-3e0a-4673-9e2d-683d8e51ff47",
   "metadata": {},
   "source": [
    "## Use ActionWeaver and Azure OpenAI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f12f7870-aa76-4755-ab89-96737ca9a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "azure_client = patch(AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2023-10-01-preview\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f342800e-fd6e-4195-9da9-44a4cc713f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current weather\n",
      "Getting current weather\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The current weather in San Francisco is 72 degrees Fahrenheit. However, I couldn't find the current weather temperature for Beijing.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"what's the weather in San Francisco and Beijing ?\"}\n",
    "  ]\n",
    "\n",
    "\n",
    "response = azure_client.chat.completions.create(\n",
    "  model=\"gpt-35-turbo-0613-16k\",\n",
    "  messages=messages,\n",
    "  stream=False,\n",
    "  actions = [get_current_weather],\n",
    "  token_usage_tracker = TokenUsageTracker(500),\n",
    "  logger=logger\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d6414-c04c-4fbe-bfeb-8cb9effc2b39",
   "metadata": {},
   "source": [
    "### Force execute an action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff6aa568-cdc5-45bc-8ee5-4c111bc347fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current time...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current time is 23:21 (11:21 PM).'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_time.invoke(openai_client, messages=[{\"role\": \"user\", \"content\": \"what time\"}], model=\"gpt-3.5-turbo\", stream=False, force=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6635698-7886-414d-9cb9-84f6ad28ccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current time...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current time is 23:21.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_time.invoke(azure_client, messages=[{\"role\": \"user\", \"content\": \"what time\"}], model=\"gpt-35-turbo-0613-16k\", stream=False, force=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e9543b-1947-4545-9d8e-7aed7833c565",
   "metadata": {},
   "source": [
    "### Stop the Action in the loop\n",
    "\n",
    "Every action comes with a stop argument, which is set to False by default, if True this means that the LLM will immediately return the function's output if chosen, but this also restricts the LLM from making multiple function calls. For instance, if asked about the weather in NYC and San Francisco, the model would invoke two separate functions sequentially for each city. However, with `stop=True`, this process is interrupted once the first function returns weather information for either NYC or San Francisco, depending on which city it queries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4178e1d-ef6c-4954-b342-729f73b4736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_current_weather.stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aad3616a-18ab-4809-893c-171a0c625245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current weather\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"}'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather.invoke(openai_client, messages=[{\"role\": \"user\", \"content\": \"what weather is San Francisco\"}], model=\"gpt-3.5-turbo\", stream=False, force=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfadce88-7bc9-41b0-9db2-926985931c69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
