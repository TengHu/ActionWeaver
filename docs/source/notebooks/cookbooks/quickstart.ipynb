{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02433815-7bb9-4e61-be67-db4854f0c403",
   "metadata": {},
   "source": [
    "# QuickStart\n",
    "\n",
    "_ActionWeaver is an AI application framework that puts function-calling as a first-class feature_.\n",
    "\n",
    "---\n",
    "\n",
    "This demonstrates how to seamlessly integrate any Python function into your LLM application using ActionWeaver and either the Azure or OpenAI API.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16250eaa-15b7-4848-81cf-ac62cd8cefa9",
   "metadata": {},
   "source": [
    "**Use ActionWeaver and OpenAI API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d682d986-a3ac-4f4d-a967-a6eaccef0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from actionweaver.utils.tokens import TokenUsageTracker\n",
    "from actionweaver.llms import patch\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_client = patch(OpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22710e02-f81f-4050-8c2c-01cd64e48f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from actionweaver import action\n",
    "\n",
    "@action(name=\"GetCurrentTime\")\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"\n",
    "    Use this for getting the current time in the specified time zone.\n",
    "    \n",
    "    :return: A string representing the current time in the specified time zone.\n",
    "    \"\"\"\n",
    "    print (\"Getting current time...\")\n",
    "    import datetime\n",
    "    current_time = datetime.datetime.now()\n",
    "    \n",
    "    return f\"The current time is {current_time}\"\n",
    "\n",
    "\n",
    "@action(name=\"GetWeather\", stop=False)\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    print (\"Getting current weather\")\n",
    "    \n",
    "    import json\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69c84261-b03b-4333-8cea-8315241c69a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current weather\n",
      "Getting current weather\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8e9y8FGK2m2srSbp4Bjk3dqBpSChZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The current weather in San Francisco is 72°F. However, I couldn't find the current weather for Beijing.\", role='assistant', function_call=None, tool_calls=None))], created=1704582132, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=24, prompt_tokens=155, total_tokens=179))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"what's the weather in San Francisco and Beijing ?\"}\n",
    "  ]\n",
    "\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=messages,\n",
    "    actions = [get_current_weather],\n",
    "    stream=False, \n",
    "    token_usage_tracker = TokenUsageTracker(500),\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e1741f-3e0a-4673-9e2d-683d8e51ff47",
   "metadata": {},
   "source": [
    "**Use ActionWeaver and Azure OpenAI Service**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f12f7870-aa76-4755-ab89-96737ca9a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "azure_client = patch(AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2023-10-01-preview\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f342800e-fd6e-4195-9da9-44a4cc713f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current weather\n",
      "Getting current weather\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8e9yKb941WGZbspsGSPjS5TzrQQs7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The weather in San Francisco is currently 72°F. However, I'm sorry, but I don't have the current weather information for Beijing.\", role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1704582144, model='gpt-35-turbo-16k', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=30, prompt_tokens=155, total_tokens=185), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"what's the weather in San Francisco and Beijing ?\"}\n",
    "  ]\n",
    "\n",
    "\n",
    "response = azure_client.chat.completions.create(\n",
    "  model=\"gpt-35-turbo-0613-16k\",\n",
    "  messages=messages,\n",
    "  stream=False,\n",
    "  actions = [get_current_weather],\n",
    "  token_usage_tracker = TokenUsageTracker(500),\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70eb220-807d-41f3-afa8-5d1c6305c6cb",
   "metadata": {},
   "source": [
    "**Easily integrate tools from libraries such as [Langchain](https://github.com/langchain-ai/langchain/tree/master/libs/community)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b6569a0-c2e1-4109-b88a-8025ed76dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.google_search.tool import GoogleSearchRun\n",
    "from langchain_community.utilities.google_search import GoogleSearchAPIWrapper\n",
    "search_tool = GoogleSearchRun(api_wrapper=GoogleSearchAPIWrapper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "568e6e30-362b-4ab6-a088-99370269c205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8eA05byBaqO8ej5eEPmEKKeHHRPAZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The weather information for San Francisco and Tokyo is not provided in the search results. However, you can use weather websites or apps to check the current weather conditions and forecast for both cities.', role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1704582253, model='gpt-35-turbo-16k', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=38, prompt_tokens=774, total_tokens=812), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"what's the weather in San Francisco and Tokyo ?\"}\n",
    "  ]\n",
    "\n",
    "from actionweaver.actions.factories.langchain import action_from_tool\n",
    "\n",
    "response = azure_client.chat.completions.create(\n",
    "  model=\"gpt-35-turbo-0613-16k\",\n",
    "  messages=messages,\n",
    "  stream=False,\n",
    "  actions = [action_from_tool(search_tool)],\n",
    "  token_usage_tracker = TokenUsageTracker(500),\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d6414-c04c-4fbe-bfeb-8cb9effc2b39",
   "metadata": {},
   "source": [
    "**Force execute an action**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff6aa568-cdc5-45bc-8ee5-4c111bc347fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current time...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8asFCTvOY4IngXDVtt35BSj8vE7Me', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The current time is 16:30.', role='assistant', function_call=None, tool_calls=None))], created=1703799014, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=98, total_tokens=108))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_time.invoke(openai_client, messages=[{\"role\": \"user\", \"content\": \"what time\"}], model=\"gpt-3.5-turbo\", stream=False, force=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6635698-7886-414d-9cb9-84f6ad28ccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current time...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8asFHNakresQO5RhS56IyTSZf76RL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The current time is 2023-12-28 16:30:19.', role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1703799019, model='gpt-35-turbo-16k', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=19, prompt_tokens=98, total_tokens=117), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_time.invoke(azure_client, messages=[{\"role\": \"user\", \"content\": \"what time\"}], model=\"gpt-35-turbo-0613-16k\", stream=False, force=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e9543b-1947-4545-9d8e-7aed7833c565",
   "metadata": {},
   "source": [
    "**Stop the Action in the loop**\n",
    "\n",
    "Every action comes with a stop argument, which is set to False by default, if True this means that the LLM will immediately return the function's output if chosen, but this also restricts the LLM from making multiple function calls. For instance, if asked about the weather in NYC and San Francisco, the model would invoke two separate functions sequentially for each city. However, with `stop=True`, this process is interrupted once the first function returns weather information for either NYC or San Francisco, depending on which city it queries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4178e1d-ef6c-4954-b342-729f73b4736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_current_weather.stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aad3616a-18ab-4809-893c-171a0c625245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current weather\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather.invoke(openai_client, messages=[{\"role\": \"user\", \"content\": \"what weather is San Francisco\"}], model=\"gpt-3.5-turbo\", stream=False, force=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
