{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02433815-7bb9-4e61-be67-db4854f0c403",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# QuickStart\n",
    "\n",
    "_AI application framework that makes function calling with LLM easier_.\n",
    "\n",
    "---\n",
    "\n",
    "This demonstrates how to seamlessly integrate any Python function into your LLM application using ActionWeaver and either the Azure or OpenAI API.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e365394b-99c6-49bc-9115-37f25ea83072",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16250eaa-15b7-4848-81cf-ac62cd8cefa9",
   "metadata": {},
   "source": [
    "**Use ActionWeaver and OpenAI API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682d986-a3ac-4f4d-a967-a6eaccef0413",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from actionweaver.utils.tokens import TokenUsageTracker\n",
    "from actionweaver.llms import wrap\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_client = wrap(OpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22710e02-f81f-4050-8c2c-01cd64e48f32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from actionweaver import action\n",
    "@action(name=\"GetCurrentTime\")\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"\n",
    "    Use this for getting the current time in the specified time zone.\n",
    "    \n",
    "    :return: A string representing the current time in the specified time zone.\n",
    "    \"\"\"\n",
    "    print (\"Getting current time...\")\n",
    "    import datetime\n",
    "    current_time = datetime.datetime.now()\n",
    "    \n",
    "    return f\"The current time is {current_time}\"\n",
    "\n",
    "\n",
    "@action(name=\"GetWeather\", stop=False)\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    print (\"Getting current weather\")\n",
    "    \n",
    "    import json\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c84261-b03b-4333-8cea-8315241c69a5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"what's the weather in San Francisco and Beijing ?\"}\n",
    "  ]\n",
    "\n",
    "response = openai_client.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=messages,\n",
    "    actions = [get_current_weather],\n",
    "    stream=False, \n",
    "    token_usage_tracker = TokenUsageTracker(500),\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e1741f-3e0a-4673-9e2d-683d8e51ff47",
   "metadata": {},
   "source": [
    "**Use ActionWeaver and Azure OpenAI Service**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f7870-aa76-4755-ab89-96737ca9a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "azure_client = wrap(AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2023-10-01-preview\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f342800e-fd6e-4195-9da9-44a4cc713f65",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"what's the weather in San Francisco and Beijing ?\"}\n",
    "  ]\n",
    "\n",
    "response = azure_client.create(\n",
    "  model=\"gpt-4-32k\",\n",
    "  messages=messages,\n",
    "  stream=False,\n",
    "  actions = [get_current_weather],\n",
    "  token_usage_tracker = TokenUsageTracker(500),\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70eb220-807d-41f3-afa8-5d1c6305c6cb",
   "metadata": {},
   "source": [
    "**Easily integrate tools from libraries such as [Langchain](https://github.com/langchain-ai/langchain/tree/master/libs/community)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6569a0-c2e1-4109-b88a-8025ed76dfab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.google_search.tool import GoogleSearchRun\n",
    "from langchain_community.utilities.google_search import GoogleSearchAPIWrapper\n",
    "search_tool = GoogleSearchRun(api_wrapper=GoogleSearchAPIWrapper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e6e30-362b-4ab6-a088-99370269c205",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"search what is ActionWeaver on Github\"}\n",
    "  ]\n",
    "\n",
    "from actionweaver.actions.factories.langchain import action_from_tool\n",
    "\n",
    "response = azure_client.create(\n",
    "  model=\"gpt-35-turbo-0613-16k\",\n",
    "  messages=messages,\n",
    "  stream=False,\n",
    "  actions = [action_from_tool(search_tool, description=\"Invoke this tool to search any information\")],\n",
    "  token_usage_tracker = TokenUsageTracker(500),\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d6414-c04c-4fbe-bfeb-8cb9effc2b39",
   "metadata": {},
   "source": [
    "**Force execute an action**\n",
    "\n",
    "You can also compel the language model to execute the action by calling the invoke method of an action. Its arguments includes the ActionWeaver-wrapped client and other arguments passed to the create API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6aa568-cdc5-45bc-8ee5-4c111bc347fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_current_time.invoke(openai_client, messages=[{\"role\": \"user\", \"content\": \"what time\"}], model=\"gpt-3.5-turbo\", stream=False, force=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6635698-7886-414d-9cb9-84f6ad28ccb2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_current_time.invoke(azure_client, messages=[{\"role\": \"user\", \"content\": \"what time\"}], model=\"gpt-35-turbo-0613-16k\", stream=False, force=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e9543b-1947-4545-9d8e-7aed7833c565",
   "metadata": {},
   "source": [
    "**Stop the Action in the loop**\n",
    "\n",
    "Every action comes with a stop argument, which is set to False by default, if True this means that the LLM will immediately return the function's output if chosen, but this also restricts the LLM from making multiple function calls. For instance, if asked about the weather in NYC and San Francisco, the model would invoke two separate functions sequentially for each city. However, with `stop=True`, this process is interrupted once the first function returns weather information for either NYC or San Francisco, depending on which city it queries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4178e1d-ef6c-4954-b342-729f73b4736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_current_weather.stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad3616a-18ab-4809-893c-171a0c625245",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_current_weather.invoke(openai_client, messages=[{\"role\": \"user\", \"content\": \"what weather is San Francisco\"}], model=\"gpt-3.5-turbo\", stream=False, force=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0dd7cd-af51-4a47-b470-5f1dff4ae3f8",
   "metadata": {},
   "source": [
    "**Actions of Stateful Agent**\n",
    "\n",
    "Developers also could create a class and enhance its functionality using ActionWeaver's action decorators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c8d3e-3c3d-4047-b662-1b358ceaed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentV0:\n",
    "    def __init__(self):\n",
    "        self.llm = wrap(OpenAI())\n",
    "        self.messages = []\n",
    "        self.times = []\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        self.messages += [{\"role\": \"user\", \"content\":text}]\n",
    "        return self.llm.create(model=\"gpt-3.5-turbo\", messages=self.messages, actions = [self.get_current_time])\n",
    "        \n",
    "    @action(name=\"GetCurrentTime\")\n",
    "    def get_current_time(self) -> str:\n",
    "        \"\"\"\n",
    "        Use this for getting the current time in the specified time zone.\n",
    "        \n",
    "        :return: A string representing the current time in the specified time zone.\n",
    "        \"\"\"\n",
    "        import datetime\n",
    "        current_time = datetime.datetime.now()\n",
    "\n",
    "        self.times += [str(current_time)]\n",
    "        \n",
    "        return f\"The current time is {current_time}\"\n",
    "\n",
    "agent = AgentV0()\n",
    "\n",
    "agent(\"what time is it\") # Output: 'The current time is 20:34.'\n",
    "\n",
    "# You can invoke actions just like regular instance methods\n",
    "agent.get_current_time() # Output: 'The current time is 20:34.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727a7e3-408f-4780-9223-38ca94f15d21",
   "metadata": {},
   "source": [
    "**Grouping and Extending Actions Through Inheritance**\n",
    "\n",
    "In this example, we wrap the LangChain Google search as a method, and define a new agent that inherits the previous agent and LangChain search tool. This approach leverages object-oriented principles to enable rapid development and easy expansion of the agent's capabilities.\n",
    "\n",
    "In the example below, through inheritance, the new agent can utilize the Google search tool method as well as any other actions defined in the parent classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aeb62d-b18a-45cf-95f7-0d776a5db021",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangChainTools:\n",
    "    @action(name=\"GoogleSearch\")\n",
    "    def google_search(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Perform a Google search using the provided query. \n",
    "        \n",
    "        This action requires `langchain` and `google-api-python-client` installed, and GOOGLE_API_KEY, GOOGLE_CSE_ID environment variables.\n",
    "        See https://python.langchain.com/docs/integrations/tools/google_search.\n",
    "\n",
    "        :param query: The search query to be used for the Google search.\n",
    "        :return: The search results as a string.\n",
    "        \"\"\"\n",
    "\n",
    "        search = GoogleSearchAPIWrapper()\n",
    "        return search.run(query)\n",
    "    \n",
    "class AgentV1(AgentV0, LangChainTools):\n",
    "    def __call__(self, text):\n",
    "        self.messages += [{\"role\": \"user\", \"content\":text}]\n",
    "        return self.llm.create(model=\"gpt-3.5-turbo\", messages=self.messages, actions = [self.google_search])\n",
    "\n",
    "agent = AgentV1()\n",
    "agent(\"what happened today\")\n",
    "\n",
    "\"\"\"\n",
    "Output: Here are some events that happened or are scheduled for today (August 23, 2023):\\n\\n1. Agreement State Event: Event Number 56678 - Maine Radiation Control Program.\\n2. Childbirth Class - August 23, 2023, at 6:00 pm.\\n3. No events scheduled for August 23, 2023, at Ambassador.\\n4. Fine Arts - Late Start.\\n5. Millersville University events.\\n6. Regular City Council Meeting - August 23, 2023, at 10:00 AM.\\n\\nPlease note that these are just a few examples, and there may be other events happening as well.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
