{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02433815-7bb9-4e61-be67-db4854f0c403",
   "metadata": {},
   "source": [
    "# Stateful Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c94281-1d38-4e34-bbd0-92ff70227482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import openai\n",
    "import itertools\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from actionweaver.llms.openai.chat import OpenAIChatCompletion\n",
    "from actionweaver.llms.openai.tokens import TokenUsageTracker\n",
    "from actionweaver import action, SelectOne, RequireNext\n",
    "\n",
    "from actionweaver.mixins.examples import LangChainTools, Folium, OpenAIAPI\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08caafb5-37ca-4c69-a893-58e3313ef9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='agent.log',\n",
    "    filemode='a',\n",
    "    format='%(asctime)s.%(msecs)04d %(levelname)s {%(module)s} [%(funcName)s] %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "079d94a0-19ba-4874-8db3-0b1f28230da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentV0:\n",
    "    def __init__(self, logger):\n",
    "        self.logger = logger\n",
    "        self.token_tracker = TokenUsageTracker(budget=None, logger=logger)\n",
    "        self.llm = OpenAIChatCompletion(\"gpt-3.5-turbo\", token_usage_tracker = self.token_tracker, logger=logger)\n",
    "        \n",
    "        self.messages = [{\"role\": \"system\", \"content\": \"You are a resourceful assistant.\"}]\n",
    "        self.times = []\n",
    "\n",
    "    def __call__(self, text):\n",
    "        self.messages += [{\"role\": \"user\", \"content\":text}]\n",
    "        response = self.llm.create(messages=self.messages, actions = [self.get_current_time, self.sleep], stream=True)\n",
    "\n",
    "        return response\n",
    "        \n",
    "    @action(name=\"GetCurrentTime\")\n",
    "    def get_current_time(self) -> str:\n",
    "        \"\"\"\n",
    "        Use this for getting the current time in the specified time zone.\n",
    "        \n",
    "        :return: A string representing the current time in the specified time zone.\n",
    "        \"\"\"\n",
    "        import datetime\n",
    "        current_time = datetime.datetime.now()\n",
    "\n",
    "        self.times += [str(current_time)]\n",
    "        \n",
    "        return f\"The current time is {current_time}\"\n",
    "\n",
    "\n",
    "    @action(name=\"Sleep\")\n",
    "    def sleep(self, seconds: int) -> str:\n",
    "        \"\"\"\n",
    "        Introduces a sleep delay of the specified seconds and returns a message.\n",
    "    \n",
    "        Args:\n",
    "            seconds (int): The duration to sleep in seconds.\n",
    "    \n",
    "        Returns:\n",
    "            str: A message indicating the completion of the sleep.\n",
    "        \"\"\"\n",
    "        import time\n",
    "        time.sleep(seconds)\n",
    "        return f\"Now I wake up after sleep {seconds} seconds.\"\n",
    "\n",
    "\n",
    "    @action(name=\"Ask\")\n",
    "    def ask(self, question: str) -> str:\n",
    "        \"\"\"\n",
    "        Invoke this if you want to ask question, or there is anything need clarification.\n",
    "    \n",
    "        Args:\n",
    "            question (str): The question to ask the user.\n",
    "        \"\"\"\n",
    "        ans = input(f\"Question: {question}\\n\")\n",
    "        return ans\n",
    "\n",
    "def print_output(output):\n",
    "    if type(output) == itertools._tee:\n",
    "        for chunk in output:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            if content is not None:\n",
    "                print(content, end='')\n",
    "    else:\n",
    "        print (output)\n",
    "\n",
    "\n",
    "agent = AgentV0(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9138451-e0b5-44bd-b768-2c9f25bbcedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current time is 11:03 AM."
     ]
    }
   ],
   "source": [
    "print_output(agent(\"what time is it\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "842e1792-3210-4be8-85c9-f6c669dfe127",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentV1(AgentV0, LangChainTools, Folium, OpenAIAPI):\n",
    "    def __call__(self, text):\n",
    "        self.messages += [{\"role\": \"user\", \"content\":text}]\n",
    "        response = self.llm.create(messages=self.messages, actions = [self.search, self.show_map, self.get_current_time, self.sleep], stream=True)\n",
    "\n",
    "        return response\n",
    "\n",
    "agent = AgentV1(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fffbbb7-c8e3-4a98-9564-01ed054c5443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain is a framework for developing applications powered by language models. It enables the creation of context-aware, reasoning applications using language models. Langchain provides a flexible set of abstractions and an extensive toolkit for developers to build applications that leverage the power of language models. It was launched as an open-source project in October 2022 by Harrison Chase, while working at machine learning startup Robust Intelligence. Langchain offers both Python and JavaScript versions for developers to use."
     ]
    }
   ],
   "source": [
    "print_output(agent(\"search what is Langchain\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b280e164-f499-410c-801e-2bf81a376c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c3a82d-d8da-4a74-9e2d-c263bceb107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileUtility(AgentV0):\n",
    "    @action(name=\"FileHandler\", orch_expr=SelectOne(['FileHandler', 'ListFiles', 'ReadFile']))\n",
    "    def handle_file(self, instruction: str) -> str:\n",
    "        \"\"\"\n",
    "        Handles user instructions related to file operations. Put every context in the instruction only!\n",
    "    \n",
    "        Args:\n",
    "            instruction (str): The user's instruction about file handling.\n",
    "    \n",
    "        Returns:\n",
    "            str: The response to the user's question.\n",
    "        \"\"\"\n",
    "        return instruction\n",
    "        \n",
    "\n",
    "    @action(name=\"ListFiles\", scope=\"file\")\n",
    "    def list_all_files_in_repo(self, repo_path: str ='.') -> List:\n",
    "        \"\"\"\n",
    "        Lists all the files in the given repository.\n",
    "    \n",
    "        :param repo_path: Path to the repository. Defaults to the current directory.\n",
    "        :return: List of file paths.\n",
    "        \"\"\"\n",
    "\n",
    "        logger.info(f\"list_all_files_in_repo: {repo_path}\")\n",
    "        \n",
    "        file_list = []\n",
    "        for root, _, files in os.walk(repo_path):\n",
    "            for file in files:\n",
    "                file_list.append(os.path.join(root, file))\n",
    "            break\n",
    "        return file_list\n",
    "\n",
    "    @action(name=\"ReadFile\", scope=\"file\")\n",
    "    def read_from_file(self, file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Reads the content of a file and returns it as a string.\n",
    "    \n",
    "        :param file_path: The path to the file that needs to be read.\n",
    "        :return: A string containing the content of the file.\n",
    "        \"\"\"\n",
    "        logger.info(f\"read_from_file: {file_path}\")\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "        return f\"The file content: \\n{content}\"\n",
    "\n",
    "    @action(name=\"WriteFile\", scope=\"file\")\n",
    "    def write_to_file(self, file_path: str, content: str) -> str:\n",
    "        \"\"\"\n",
    "        Writes the given content to a file.\n",
    "        \n",
    "        :param file_path: The path to the file where the content should be written.\n",
    "        :param content: The content to be written to the file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'a') as file:\n",
    "                file.write(content)\n",
    "            return \"Content successfully appended to the file.\"\n",
    "        except Exception as e:\n",
    "            return f\"An error occurred while appending to the file: {str(e)}\"\n",
    "        \n",
    "\n",
    "\n",
    "class AgentV2(FileUtility):\n",
    "    def __call__(self, text):\n",
    "        self.messages += [{\"role\": \"user\", \"content\":text}]\n",
    "        response = self.llm.create(messages=self.messages, actions = [self.search, self.show_map, self.get_current_time, self.sleep], stream=True)\n",
    "\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74993086-26fb-415e-b37e-d5cb1914b2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3afcae-1d71-47ed-9870-0922e97a75d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c862b6c-12c0-4a4c-ad12-dfc420e7985c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbecb67-b8ac-4492-ae5b-980650907dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
